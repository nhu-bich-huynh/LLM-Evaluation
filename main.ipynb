{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Generation Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies (First, look at README)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\oskar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import import_ipynb\n",
    "import tampering_strategies as ts\n",
    "import data_sampling as ds\n",
    "from google import genai\n",
    "import Levenshtein\n",
    "from random_word import RandomWords\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pandas\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate import meteor\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"English\"\n",
    "\n",
    "# with open(\"../en.en\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     for i in range(200):\n",
    "#         lines = [next(f).strip() for _ in range(10000)]\n",
    "#         df = pandas.DataFrame({\"Text\": lines})\n",
    "#         output_file = f\"dataframes/en/{name}{i+1}.csv\"\n",
    "#         df.to_csv(output_file, index=False, encoding=\"utf-8\", quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# name = \"Danish\"\n",
    "\n",
    "# with open(\"../da.da\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     for i in range(200):\n",
    "#         lines = [next(f).strip() for _ in range(10000)]\n",
    "#         df = pandas.DataFrame({\"Text\": lines})\n",
    "#         output_file = f\"dataframes/da/{name}{i+1}.csv\"\n",
    "#         df.to_csv(output_file, index=False, encoding=\"utf-8\", quoting=csv.QUOTE_ALL)\n",
    "\n",
    "\n",
    "# danishData = pandas.read_fwf(\"test.txt\", header=None, names=[\"test_sentences\"])\n",
    "# englishData = pandas.read_fwf(\"test.txt\", header=None, names=[\"test_sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "r = RandomWords()\n",
    "\n",
    "def calculate_rouge(candidate, reference):\n",
    "    scores = rouge.get_scores(candidate, reference)\n",
    "    return scores\n",
    "\n",
    "def calculate_bleu(candidate, reference):\n",
    "    reference_p = [word_tokenize(reference)]\n",
    "    candidate_p = word_tokenize(candidate)\n",
    "    score = sentence_bleu(reference_p, candidate_p)\n",
    "    return score\n",
    "\n",
    "def calculate_meteor(candidate, reference):\n",
    "  reference = word_tokenize(reference)\n",
    "  candidate = word_tokenize(candidate)\n",
    "  meteor_score = round(meteor([candidate],reference), 4)\n",
    "  return meteor_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Rouge test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}]\n"
     ]
    }
   ],
   "source": [
    "sen1 = \"jeg vil gerne\"\n",
    "sen2 = \"jeg vil gerne\"\n",
    "res = calculate_rouge(sen1, sen2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform BLEU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2213386697554703e-77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Oskar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "print(calculate_bleu(sen1, sen2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform METEOR test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613\n"
     ]
    }
   ],
   "source": [
    "print(calculate_meteor(sen1, sen2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE/RESET OUTPUT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetTests(outputName):\n",
    "    name = outputName\n",
    "    cols = [\"originalSentence\", \"referenceSentence\", \"tamperingType\", \"tamperedSentence\", \"LLMScore (Sim, Con)\", \"BLEU\", \"METEOR\", \"Rouge1 r\", \"Rouge1 p\", \"Rouge1 f\", \"Rouge2 r\", \"Rouge2 p\", \"Rouge2 f\", \"Rougel r\", \"Rougel p\", \"Rougel f\", \"LLM-Sim\", \"LLM-Con\", \"originalLanguage\"]\n",
    "\n",
    "    with open(name, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=cols)\n",
    "        writer.writeheader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\oskar\\AppData\\Local\\Temp\\ipykernel_9968\\3491709956.py:93: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '(1.00, 1.00)' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[index, \"LLMScore (Sim, Con)\"] = llmResClean\n",
      "C:\\Users\\oskar\\AppData\\Local\\Temp\\ipykernel_9968\\3491709956.py:100: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.00' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[index, \"LLM-Sim\"] = sim\n",
      "C:\\Users\\oskar\\AppData\\Local\\Temp\\ipykernel_9968\\3491709956.py:101: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.00' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data.at[index, \"LLM-Con\"] = con\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 111\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Test(Name of source language file, name of reference language file, number of output (1000), True, \"da\"/\"en\" (source language), output name)\u001b[39;00m\n\u001b[0;32m    110\u001b[0m resetTests(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m \u001b[43mTest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataframes/da/Danish1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataframes/en/English1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAIzaSyBmaHo7qlcKq8B5NA1S9qD-d0sG0rBzKps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m resetTests(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m Test(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframes/en/English2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframes/da/Danish2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyC9qmWHbIbyRap-BEWLovQodE2goc2bJe8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 107\u001b[0m, in \u001b[0;36mTest\u001b[1;34m(sourceFile, refFile, outputSize, llm, sourceLanguage, outputName, key)\u001b[0m\n\u001b[0;32m    104\u001b[0m     data\u001b[38;5;241m.\u001b[39mto_csv(outputName, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m testDataSets(sourceFile, refFile)\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m llm: \u001b[43maddLLMScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputName\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 88\u001b[0m, in \u001b[0;36mTest.<locals>.addLLMScore\u001b[1;34m(res)\u001b[0m\n\u001b[0;32m     86\u001b[0m danish \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreferenceSentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     87\u001b[0m tamp \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtamperedSentence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemini-2.0-flash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmakePrompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdanish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m llmRes \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     92\u001b[0m llmResClean \u001b[38;5;241m=\u001b[39m llmRes\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\models.py:5286\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   5284\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   5285\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5286\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5287\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m   5288\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5289\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   5290\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\models.py:4256\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[1;34m(self, model, contents, config)\u001b[0m\n\u001b[0;32m   4253\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[0;32m   4254\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[1;32m-> 4256\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4257\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[0;32m   4258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n\u001b[0;32m   4261\u001b[0m   response_dict \u001b[38;5;241m=\u001b[39m _GenerateContentResponse_from_vertex(\n\u001b[0;32m   4262\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client, response_dict\n\u001b[0;32m   4263\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\_api_client.py:557\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[1;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    549\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    552\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    553\u001b[0m ):\n\u001b[0;32m    554\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[0;32m    555\u001b[0m       http_method, path, request_dict, http_options\n\u001b[0;32m    556\u001b[0m   )\n\u001b[1;32m--> 557\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m   json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson\n\u001b[0;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\_api_client.py:471\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    467\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    468\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    469\u001b[0m   )\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 471\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_unauthorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\_api_client.py:494\u001b[0m, in \u001b[0;36mBaseApiClient._request_unauthorized\u001b[1;34m(self, http_request, stream)\u001b[0m\n\u001b[0;32m    485\u001b[0m http_session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m    486\u001b[0m response \u001b[38;5;241m=\u001b[39m http_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    487\u001b[0m     method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    493\u001b[0m )\n\u001b[1;32m--> 494\u001b[0m \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[0;32m    496\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[0;32m    497\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\genai\\errors.py:116\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[1;34m(cls, response)\u001b[0m\n\u001b[0;32m    114\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m--> 116\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(status_code, response)\n",
      "\u001b[1;31mServerError\u001b[0m: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}"
     ]
    }
   ],
   "source": [
    "def Test(sourceFile, refFile, outputSize, llm, sourceLanguage, outputName, key):\n",
    "    propLenIndeces = ds.properLengthIndeces(sourceFile)\n",
    "    negIndeces = ds.negationIndeces(sourceFile, sourceLanguage)\n",
    "    tampStrats = 10\n",
    "    sensPerTamp = int(outputSize / tampStrats)\n",
    "\n",
    "    indcsNeg = ds.getXRandomIndeces(sensPerTamp, negIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(negIndeces))\n",
    "    indcs1 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs1))\n",
    "    indcs2 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs2))\n",
    "    indcs3 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs3))\n",
    "    indcs4 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs4))\n",
    "    indcs5 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs5))\n",
    "    indcs6 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs6))\n",
    "    indcs7 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs7))\n",
    "    indcs8 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "    propLenIndeces = list(set(propLenIndeces)-set(indcs8))\n",
    "    indcs9 = ds.getXRandomIndeces(sensPerTamp, propLenIndeces)\n",
    "\n",
    "    def runTest(oriSen, tamp, tampType, refSen):\n",
    "        columns = [\"originalSentence\", \"referenceSentence\", \"tamperingType\", \"tamperedSentence\", \"LLMScore (Sim, Con)\", \"BLEU\", \"METEOR\", \"Rouge1 r\", \"Rouge1 p\", \"Rouge1 f\", \"Rouge2 r\", \"Rouge2 p\", \"Rouge2 f\", \"Rougel r\", \"Rougel p\", \"Rougel f\", \"LLM-Sim\", \"LLM-Con\", \"originalLanguage\"]\n",
    "        tampSen = tamp(oriSen, sourceLanguage)\n",
    "        if tampSen[0]:\n",
    "            rouge = calculate_rouge(oriSen, tampSen[1])\n",
    "            res = {\"originalSentence\": oriSen, \"referenceSentence\": refSen, \"tamperingType\": tampType, \"tamperedSentence\": tampSen[1], \"LLMScore (Sim, Con)\": -1, \"BLEU\": calculate_bleu(oriSen, tampSen[1]), \"METEOR\": calculate_meteor(oriSen, tampSen[1]), \"Rouge1 r\": rouge[0][\"rouge-1\"]['r'], \"Rouge1 p\": rouge[0][\"rouge-1\"]['p'], \"Rouge1 f\": rouge[0][\"rouge-1\"]['f'], \"Rouge2 r\": rouge[0][\"rouge-2\"]['r'], \"Rouge2 p\": rouge[0][\"rouge-2\"]['p'], \"Rouge2 f\": rouge[0][\"rouge-2\"]['f'], \"Rougel r\": rouge[0][\"rouge-l\"]['r'], \"Rougel p\": rouge[0][\"rouge-l\"]['p'], \"Rougel f\": rouge[0][\"rouge-l\"]['f'], \"LLM-Sim\": \"NULL\", \"LLM-Con\": \"NULL\", \"originalLanguage\": sourceLanguage}\n",
    "            with open(outputName, mode=\"a\", newline=\"\", encoding='utf-8') as file:\n",
    "                writer = csv.DictWriter(file, fieldnames=columns)\n",
    "                \n",
    "                writer.writerow(res)\n",
    "\n",
    "\n",
    "    def testAllTamps(oriSen, refSen, indx):\n",
    "        if indx in indcs1: runTest(oriSen.lower(), ts.replaceWithRandomWord, \"Replace Token with Random Word\", refSen.lower())\n",
    "        if indx in indcs2: runTest(oriSen.lower(), ts.swapWords, \"Swap words\", refSen.lower())\n",
    "        if indx in indcs3: runTest(oriSen.lower(), ts.removeToken, \"Remove Token\", refSen.lower())\n",
    "        if indx in indcs4: runTest(oriSen.lower(), ts.addRandomWord, \"Add random word\", refSen.lower())\n",
    "        if indx in indcs5: runTest(oriSen.lower(), ts.duplicateToken, \"Duplicate Token\", refSen.lower())\n",
    "        if indx in indcs6: runTest(oriSen.lower(), ts.replaceCharacter, \"Replace Character\", refSen.lower())\n",
    "        if indx in indcs7: runTest(oriSen.lower(), ts.duplicateCharacter, \"Duplicate character\", refSen.lower())\n",
    "        if indx in indcs8: runTest(oriSen.lower(), ts.removeCharacter, \"Remove Character\" , refSen.lower())\n",
    "        if indx in indcs9: runTest(oriSen.lower(), ts.swapCharacters, \"Swap characters\", refSen.lower())\n",
    "        if indx in indcsNeg: runTest(oriSen.lower(), ts.negation, \"Negation\", refSen.lower())\n",
    "        \n",
    "\n",
    "    def testDataSets(sou, ref):\n",
    "        souSens = pandas.read_csv(sou, encoding='utf-8')\n",
    "        refSens = pandas.read_csv(ref, encoding='utf-8')\n",
    "        for index, row in souSens.iterrows():\n",
    "            original = row[\"Text\"]\n",
    "            transRef = refSens.iloc[index][\"Text\"]\n",
    "            testAllTamps(original, transRef, index)\n",
    "\n",
    "    def makePrompt(ref, sou, tamp):\n",
    "        if sourceLanguage == \"en\": res = f\"\"\"Here are two sentences perfectly translated from Danish into English:\n",
    "\n",
    "        Sentence 1: {ref}\n",
    "        Sentence 2: {sou}\n",
    "\n",
    "    Now I will give you a third sentence, which is another translation in English. Compare the semantic similarity between sentence 2 and 3 on a scale from 0.00 (totally different) to 1.00 (totally identical). Also give an estimate of how confident you are about this similarity score on a scale from 0.00 (no confidence) to 1.00 (maximum confidence). Return ONLY a tuple where the first element is the similarity score and the second element is the confidence score.\n",
    "\n",
    "        Sentence 3: {tamp}\"\"\"\n",
    "            \n",
    "        if sourceLanguage == \"da\": res = f\"\"\"Here are two sentences perfectly translated from English into Danish:\n",
    "\n",
    "        Sentence 1: {ref}\n",
    "        Sentence 2: {sou}\n",
    "\n",
    "    Now I will give you a third sentence, which is another translation in Danish. Compare the semantic similarity between sentence 2 and 3 on a scale from 0.00 (totally different) to 1.00 (totally identical). Also give an estimate of how confident you are about this similarity score on a scale from 0.00 (no confidence) to 1.00 (maximum confidence). Return ONLY a tuple where the first element is the similarity score and the second element is the confidence score.\n",
    "\n",
    "        Sentence 3: {tamp}\"\"\"\n",
    "\n",
    "        return res\n",
    "\n",
    "    def addLLMScore(res):\n",
    "        client = genai.Client(api_key=key)\n",
    "        data = pandas.read_csv(res, encoding='utf-8')\n",
    "        for index, row in data.iterrows():\n",
    "            english = row[\"originalSentence\"]\n",
    "            danish = row[\"referenceSentence\"]\n",
    "            tamp = row[\"tamperedSentence\"]\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\", contents=makePrompt(danish, english, tamp)\n",
    "            )\n",
    "            llmRes = response.text\n",
    "            llmResClean = llmRes.replace(\"\\n\",\"\")\n",
    "            data.at[index, \"LLMScore (Sim, Con)\"] = llmResClean\n",
    "            LLMTotal = llmResClean\n",
    "            LLMSplit = LLMTotal.split(\",\")\n",
    "            sim = LLMSplit[0]\n",
    "            con = LLMSplit[1]\n",
    "            sim = \"\".join(filter(lambda char: char != \")\" and char != \"(\" and char != \",\" and char != \" \", sim))\n",
    "            con = \"\".join(filter(lambda char: char != \")\" and char != \"(\" and char != \",\" and char != \" \", con))\n",
    "            data.at[index, \"LLM-Sim\"] = sim\n",
    "            data.at[index, \"LLM-Con\"] = con\n",
    "            time.sleep(4)\n",
    "        \n",
    "        data.to_csv(outputName, index=False, encoding='utf-8')\n",
    "\n",
    "    testDataSets(sourceFile, refFile)\n",
    "    if llm: addLLMScore(outputName)\n",
    "\n",
    "key1 = \"AIzaSyBmaHo7qlcKq8B5NA1S9qD-d0sG0rBzKps\"\n",
    "key2 = \"AIzaSyC9qmWHbIbyRap-BEWLovQodE2goc2bJe8\"\n",
    "key3 = \"AIzaSyBEx6cNuDD9XgrV0oO10TZ7ZQzzddCr_r8\"\n",
    "\n",
    "# Test(Name of source language file, name of reference language file, number of output (1000), True, \"da\"/\"en\" (source language), output name)\n",
    "resetTests(\"output1.csv\")\n",
    "Test(\"dataframes/da/Danish1.csv\", \"dataframes/en/English1.csv\", 1000, True, \"da\", \"output1.csv\", key3)\n",
    "resetTests(\"output2.csv\")\n",
    "Test(\"dataframes/en/English2.csv\", \"dataframes/da/Danish2.csv\", 1000, True, \"en\", \"output2.csv\", key2)\n",
    "resetTests(\"output5.csv\")\n",
    "Test(\"dataframes/da/Danish5.csv\", \"dataframes/en/English5.csv\", 1000, True, \"da\", \"output5.csv\", key1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
