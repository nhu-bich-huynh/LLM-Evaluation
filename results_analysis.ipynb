{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"final_output/combinedOutput_cleaned.csv\"\n",
    "df = pandas.read_csv(file_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LLM-Con\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LLM-Sim\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"final_output/daOutput_cleaned.csv\"\n",
    "df_da = pandas.read_csv(file_path, encoding='utf-8')\n",
    "df_da.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"final_output/enOutput_cleaned.csv\"\n",
    "df_en = pandas.read_csv(file_path, encoding='utf-8')\n",
    "df_en.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['BLEU', 'METEOR', 'Rouge1 r', 'Rouge1 p', 'Rouge1 f', 'Rouge2 r', 'Rouge2 p', 'Rouge2 f', \n",
    "                       'Rougel r', 'Rougel p', 'Rougel f', 'LLM-Sim', 'LLM-Con']\n",
    "\n",
    "mean_by_strategy = df.groupby(\"tamperingType\")[columns_of_interest].mean()\n",
    "mean_global = df.groupby(\"tamperingType\")[columns_of_interest].mean()\n",
    "median_by_strategy = df.groupby(\"tamperingType\")[columns_of_interest].median()\n",
    "std_by_strategy = df.groupby(\"tamperingType\")[columns_of_interest].std()\n",
    "\n",
    "print(\"Mean by Tampering Strategy:\\n\", mean_by_strategy)\n",
    "print(\"\\nMedian by Tampering Strategy:\\n\", median_by_strategy)\n",
    "print(\"\\nStandard Deviation by Tampering Strategy:\\n\", std_by_strategy)\n",
    "\n",
    "mean_values = df[columns_of_interest].mean()\n",
    "median_values = df[columns_of_interest].median()\n",
    "std_values = df[columns_of_interest].std()\n",
    "\n",
    "print(\"\\nOverall Mean:\\n\", mean_values)\n",
    "print(\"\\nOverall Median:\\n\", median_values)\n",
    "print(\"\\nOverall Standard Deviation:\\n\", std_values)\n",
    "\n",
    "z_scores = (mean_by_strategy - mean_values) / std_values\n",
    "print(\"\\nZ-scores for Tampering Strategies:\\n\", z_scores)\n",
    "\n",
    "def z_bin(value):\n",
    "    if value > 0.5:\n",
    "        return \"High\"\n",
    "    elif value < -0.5:\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Medium\"\n",
    "\n",
    "z_bins = z_scores.applymap(z_bin)\n",
    "print(\"\\nZ-Score Bins (Low/Medium/High):\\n\", z_bins)\n",
    "\n",
    "percentile_bins = mean_by_strategy.rank(method='first').apply(\n",
    "    lambda col: pandas.qcut(col, q=[0, 0.3, 0.7, 1.0], labels=[\"Low\", \"Medium\", \"High\"])\n",
    ")\n",
    "\n",
    "print(\"\\nPercentile Bins (Low/Medium/High):\\n\", percentile_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['BLEU', 'METEOR', 'Rouge1 r', 'Rouge1 p', 'Rouge1 f', 'Rouge2 r', 'Rouge2 p', 'Rouge2 f', \n",
    "                       'Rougel r', 'Rougel p', 'Rougel f', 'LLM-Sim', 'LLM-Con']\n",
    "\n",
    "mean_by_strategy_en = df_en.groupby(\"tamperingType\")[columns_of_interest].mean()\n",
    "median_by_strategy_en = df_en.groupby(\"tamperingType\")[columns_of_interest].median()\n",
    "std_by_strategy_en = df_en.groupby(\"tamperingType\")[columns_of_interest].std()\n",
    "\n",
    "print(\"Mean by Tampering Strategy:\\n\", mean_by_strategy_en)\n",
    "print(\"\\nMedian by Tampering Strategy:\\n\", median_by_strategy_en)\n",
    "print(\"\\nStandard Deviation by Tampering Strategy:\\n\", std_by_strategy_en)\n",
    "\n",
    "mean_values_en = df_en[columns_of_interest].mean()\n",
    "median_values_en = df_en[columns_of_interest].median()\n",
    "std_values_en = df_en[columns_of_interest].std()\n",
    "\n",
    "print(\"\\nOverall Mean:\\n\", mean_values_en)\n",
    "print(\"\\nOverall Median:\\n\", median_values_en)\n",
    "print(\"\\nOverall Standard Deviation:\\n\", std_values_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danish Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['BLEU', 'METEOR', 'Rouge1 r', 'Rouge1 p', 'Rouge1 f', 'Rouge2 r', 'Rouge2 p', 'Rouge2 f', \n",
    "                       'Rougel r', 'Rougel p', 'Rougel f', 'LLM-Sim', 'LLM-Con']\n",
    "\n",
    "mean_by_strategy_da = df_da.groupby(\"tamperingType\")[columns_of_interest].mean()\n",
    "median_by_strategy_da = df_da.groupby(\"tamperingType\")[columns_of_interest].median()\n",
    "std_by_strategy_da = df_da.groupby(\"tamperingType\")[columns_of_interest].std()\n",
    "\n",
    "print(\"Mean by Tampering Strategy:\\n\", mean_by_strategy_da)\n",
    "print(\"\\nMedian by Tampering Strategy:\\n\", median_by_strategy_da)\n",
    "print(\"\\nStandard Deviation by Tampering Strategy:\\n\", std_by_strategy_da)\n",
    "\n",
    "mean_values_da = df_da[columns_of_interest].mean()\n",
    "median_values_da = df_da[columns_of_interest].median()\n",
    "std_values_da = df_da[columns_of_interest].std()\n",
    "\n",
    "print(\"\\nOverall Mean:\\n\", mean_values_da)\n",
    "print(\"\\nOverall Median:\\n\", median_values_da)\n",
    "print(\"\\nOverall Standard Deviation:\\n\", std_values_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots mean and median for each metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mean_by_strategy.index.to_list() == median_by_strategy.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df[\"tamperingType\"].unique()\n",
    "\n",
    "width = 0.2 \n",
    "x = np.arange(len(tampering_types)) \n",
    "\n",
    "for column in columns_of_interest:\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))  \n",
    "\n",
    "    mean_values = mean_by_strategy[column].values\n",
    "    median_values = median_by_strategy[column].values\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, mean_values, width, label=f'Mean {column}', color='blue')\n",
    "\n",
    "    bars2 = ax.bar(x + width/2, median_values, width, label=f'Median {column}', color='orange')\n",
    "\n",
    "    for bar in bars1:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.04, \n",
    "                f'{bar.get_height():.2f}', ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    for bar in bars2:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.04, \n",
    "                f'{bar.get_height():.2f}', ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title(f'Mean vs Median for {column} - Combined Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(mean_by_strategy.index, rotation = 20, fontsize=12) \n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mean_by_strategy_en.index.to_list() == median_by_strategy_en.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df_en[\"tamperingType\"].unique()\n",
    "\n",
    "width = 0.2 \n",
    "x = np.arange(len(tampering_types)) \n",
    "\n",
    "for column in columns_of_interest:\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))  \n",
    "\n",
    "    mean_values_en = mean_by_strategy_en[column].values\n",
    "    median_values_en = median_by_strategy_en[column].values\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, mean_values_en, width, label=f'Mean {column}', color='blue')\n",
    "\n",
    "    bars2 = ax.bar(x + width/2, median_values_en, width, label=f'Median {column}', color='orange')\n",
    "\n",
    "    for bar in bars1:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.04, \n",
    "                f'{bar.get_height():.2f}', ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    for bar in bars2:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.04, \n",
    "                f'{bar.get_height():.2f}', ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title(f'Mean vs Median for {column} - English Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(mean_by_strategy_en.index, rotation = 20, fontsize=12) \n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danish Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mean_by_strategy_da.index.to_list() == median_by_strategy_da.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df_da[\"tamperingType\"].unique()\n",
    "\n",
    "width = 0.2 \n",
    "x = np.arange(len(tampering_types)) \n",
    "\n",
    "for column in columns_of_interest:\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))  \n",
    "\n",
    "    mean_values_da = mean_by_strategy_da[column].values\n",
    "    median_values_da = median_by_strategy_da[column].values\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, mean_values_da, width, label=f'Mean {column}', color='blue')\n",
    "\n",
    "    bars2 = ax.bar(x + width/2, median_values_da, width, label=f'Median {column}', color='orange')\n",
    "\n",
    "    for bar in bars1:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.04, \n",
    "                f'{bar.get_height():.2f}', ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    for bar in bars2:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.04, \n",
    "                f'{bar.get_height():.2f}', ha='center', va='top', fontsize=10, color='black')\n",
    "\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title(f'Mean vs Median for {column} - Danish Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(mean_by_strategy_da.index, rotation = 20, fontsize=12) \n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error bars using mean and std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df[\"tamperingType\"].unique()\n",
    "\n",
    "bleu_mean = df.groupby(\"tamperingType\")[\"BLEU\"].mean()\n",
    "meteor_mean = df.groupby(\"tamperingType\")[\"METEOR\"].mean()\n",
    "rouge_mean = df.groupby(\"tamperingType\")[\"Rougel f\"].mean()  \n",
    "llm_mean = df.groupby(\"tamperingType\")[\"LLM-Sim\"].mean()\n",
    "\n",
    "\n",
    "bleu_std = df.groupby(\"tamperingType\")[\"BLEU\"].std()\n",
    "meteor_std = df.groupby(\"tamperingType\")[\"METEOR\"].std()\n",
    "rouge_std = df.groupby(\"tamperingType\")[\"Rougel f\"].std()\n",
    "llm_std = df.groupby(\"tamperingType\")[\"LLM-Sim\"].std()\n",
    "\n",
    "assert bleu_mean.index.to_list() == meteor_mean.index.to_list() == rouge_mean.index.to_list() == llm_mean.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(tampering_types))  \n",
    "width = 0.2 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, bleu_mean, width, yerr=bleu_std, capsize=5, label=\"BLEU\", color=\"blue\")\n",
    "\n",
    "bars2 = ax.bar(x, meteor_mean, width, yerr=meteor_std, capsize=5, label=\"METEOR\", color=\"orange\")\n",
    "\n",
    "bars3 = ax.bar(x + width, rouge_mean, width, yerr=rouge_std, capsize=5, label=\"ROUGE-L F1\", color=\"green\")\n",
    "\n",
    "bars4 = ax.bar(x + width*2, llm_mean, width, yerr=llm_std, capsize=5, label=\"LLM Score\", color=\"red\")\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of BLEU, METEOR, ROUGE-L (F1), and LLM Score with Error Bars - Combined Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bleu_mean.index, rotation=30, fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df_en[\"tamperingType\"].unique()\n",
    "\n",
    "bleu_mean_en = df_en.groupby(\"tamperingType\")[\"BLEU\"].mean()\n",
    "meteor_mean_en = df_en.groupby(\"tamperingType\")[\"METEOR\"].mean()\n",
    "rouge_mean_en = df_en.groupby(\"tamperingType\")[\"Rougel f\"].mean()  \n",
    "llm_mean_en = df_en.groupby(\"tamperingType\")[\"LLM-Sim\"].mean()\n",
    "\n",
    "\n",
    "bleu_std_en = df_en.groupby(\"tamperingType\")[\"BLEU\"].std()\n",
    "meteor_std_en = df_en.groupby(\"tamperingType\")[\"METEOR\"].std()\n",
    "rouge_std_en = df_en.groupby(\"tamperingType\")[\"Rougel f\"].std()\n",
    "llm_std_en = df_en.groupby(\"tamperingType\")[\"LLM-Sim\"].std()\n",
    "\n",
    "assert bleu_mean_en.index.to_list() == meteor_mean_en.index.to_list() == rouge_mean_en.index.to_list() == llm_mean_en.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(tampering_types))  \n",
    "width = 0.2 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, bleu_mean_en, width, yerr=bleu_std_en, capsize=5, label=\"BLEU\", color=\"blue\")\n",
    "\n",
    "bars2 = ax.bar(x, meteor_mean_en, width, yerr=meteor_std_en, capsize=5, label=\"METEOR\", color=\"orange\")\n",
    "\n",
    "bars3 = ax.bar(x + width, rouge_mean_en, width, yerr=rouge_std_en, capsize=5, label=\"ROUGE-L F1\", color=\"green\")\n",
    "\n",
    "bars4 = ax.bar(x + width*2, llm_mean_en, width, yerr=llm_std_en, capsize=5, label=\"LLM Score\", color=\"red\")\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of BLEU, METEOR, ROUGE-L (F1), and LLM Score with Error Bars - English Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bleu_mean_en.index, rotation=30, fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danish Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df_da[\"tamperingType\"].unique()\n",
    "\n",
    "bleu_mean_da = df_da.groupby(\"tamperingType\")[\"BLEU\"].mean()\n",
    "meteor_mean_da = df_da.groupby(\"tamperingType\")[\"METEOR\"].mean()\n",
    "rouge_mean_da = df_da.groupby(\"tamperingType\")[\"Rougel f\"].mean()  \n",
    "llm_mean_da = df_da.groupby(\"tamperingType\")[\"LLM-Sim\"].mean()\n",
    "\n",
    "\n",
    "bleu_std_da = df_da.groupby(\"tamperingType\")[\"BLEU\"].std()\n",
    "meteor_std_da = df_da.groupby(\"tamperingType\")[\"METEOR\"].std()\n",
    "rouge_std_da = df_da.groupby(\"tamperingType\")[\"Rougel f\"].std()\n",
    "llm_std_da = df_da.groupby(\"tamperingType\")[\"LLM-Sim\"].std()\n",
    "\n",
    "assert bleu_mean_da.index.to_list() == meteor_mean_da.index.to_list() == rouge_mean_da.index.to_list() == llm_mean_da.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(len(tampering_types))  \n",
    "width = 0.2 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, bleu_mean_da, width, yerr=bleu_std_da, capsize=5, label=\"BLEU\", color=\"blue\")\n",
    "\n",
    "bars2 = ax.bar(x, meteor_mean_da, width, yerr=meteor_std_da, capsize=5, label=\"METEOR\", color=\"orange\")\n",
    "\n",
    "bars3 = ax.bar(x + width, rouge_mean_da, width, yerr=rouge_std_da, capsize=5, label=\"ROUGE-L F1\", color=\"green\")\n",
    "\n",
    "bars4 = ax.bar(x + width*2, llm_mean_da, width, yerr=llm_std_da, capsize=5, label=\"LLM Score\", color=\"red\")\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of BLEU, METEOR, ROUGE-L (F1), and LLM Score with Error Bars - Danish Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bleu_mean_da.index, rotation=30, fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error bars using mean and min/max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df[\"tamperingType\"].unique()\n",
    "\n",
    "bleu_mean = df.groupby(\"tamperingType\")[\"BLEU\"].mean()\n",
    "meteor_mean = df.groupby(\"tamperingType\")[\"METEOR\"].mean()\n",
    "rouge_mean = df.groupby(\"tamperingType\")[\"Rougel f\"].mean()\n",
    "llm_mean = df.groupby(\"tamperingType\")[\"LLM-Sim\"].mean()\n",
    "\n",
    "bleu_min = df.groupby(\"tamperingType\")[\"BLEU\"].min()\n",
    "bleu_max = df.groupby(\"tamperingType\")[\"BLEU\"].max()\n",
    "\n",
    "meteor_min = df.groupby(\"tamperingType\")[\"METEOR\"].min()\n",
    "meteor_max = df.groupby(\"tamperingType\")[\"METEOR\"].max()\n",
    "\n",
    "rouge_min = df.groupby(\"tamperingType\")[\"Rougel f\"].min()\n",
    "rouge_max = df.groupby(\"tamperingType\")[\"Rougel f\"].max()\n",
    "\n",
    "llm_min = df.groupby(\"tamperingType\")[\"LLM-Sim\"].min()\n",
    "llm_max = df.groupby(\"tamperingType\")[\"LLM-Sim\"].max()\n",
    "\n",
    "assert bleu_mean.index.to_list() == meteor_mean.index.to_list() == rouge_mean.index.to_list() == llm_mean.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_errors = [bleu_mean - bleu_min, bleu_max - bleu_mean]\n",
    "meteor_errors = [meteor_mean - meteor_min, meteor_max - meteor_mean]\n",
    "rouge_errors = [rouge_mean - rouge_min, rouge_max - rouge_mean]\n",
    "llm_errors = [llm_mean - llm_min, llm_max - llm_mean]\n",
    "\n",
    "x = np.arange(len(tampering_types))  \n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, bleu_mean, width, yerr=bleu_errors, capsize=5, label=\"BLEU\", color=\"blue\")\n",
    "\n",
    "bars2 = ax.bar(x, meteor_mean, width, yerr=meteor_errors, capsize=5, label=\"METEOR\", color=\"orange\")\n",
    "\n",
    "bars3 = ax.bar(x + width, rouge_mean, width, yerr=rouge_errors, capsize=5, label=\"ROUGE-L F1\", color=\"green\")\n",
    "\n",
    "bars4 = ax.bar(x + width*2, llm_mean, width, yerr=llm_errors, capsize=5, label=\"LLM Score\", color=\"red\")\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of BLEU, METEOR, ROUGE-L (F1) and LLM Score with Min/Max Error Bars - Combined Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bleu_mean.index, rotation=30, fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df_en[\"tamperingType\"].unique()\n",
    "\n",
    "bleu_mean_en = df_en.groupby(\"tamperingType\")[\"BLEU\"].mean()\n",
    "meteor_mean_en = df_en.groupby(\"tamperingType\")[\"METEOR\"].mean()\n",
    "rouge_mean_en = df_en.groupby(\"tamperingType\")[\"Rougel f\"].mean()\n",
    "llm_mean_en = df_en.groupby(\"tamperingType\")[\"LLM-Sim\"].mean()\n",
    "\n",
    "bleu_min_en = df_en.groupby(\"tamperingType\")[\"BLEU\"].min()\n",
    "bleu_max_en = df_en.groupby(\"tamperingType\")[\"BLEU\"].max()\n",
    "\n",
    "meteor_min_en = df_en.groupby(\"tamperingType\")[\"METEOR\"].min()\n",
    "meteor_max_en = df_en.groupby(\"tamperingType\")[\"METEOR\"].max()\n",
    "\n",
    "rouge_min_en = df_en.groupby(\"tamperingType\")[\"Rougel f\"].min()\n",
    "rouge_max_en = df_en.groupby(\"tamperingType\")[\"Rougel f\"].max()\n",
    "\n",
    "llm_min_en = df_en.groupby(\"tamperingType\")[\"LLM-Sim\"].min()\n",
    "llm_max_en = df_en.groupby(\"tamperingType\")[\"LLM-Sim\"].max()\n",
    "\n",
    "assert bleu_mean_en.index.to_list() == meteor_mean_en.index.to_list() == rouge_mean_en.index.to_list() == llm_mean_en.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_errors_en = [bleu_mean_en - bleu_min_en, bleu_max_en - bleu_mean_en]\n",
    "meteor_errors_en = [meteor_mean_en - meteor_min_en, meteor_max_en - meteor_mean_en]\n",
    "rouge_errors_en = [rouge_mean_en - rouge_min_en, rouge_max_en - rouge_mean_en]\n",
    "llm_errors_en = [llm_mean_en - llm_min_en, llm_max_en - llm_mean_en]\n",
    "\n",
    "x = np.arange(len(tampering_types))  \n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, bleu_mean_en, width, yerr=bleu_errors_en, capsize=5, label=\"BLEU\", color=\"blue\")\n",
    "\n",
    "bars2 = ax.bar(x, meteor_mean_en, width, yerr=meteor_errors_en, capsize=5, label=\"METEOR\", color=\"orange\")\n",
    "\n",
    "bars3 = ax.bar(x + width, rouge_mean_en, width, yerr=rouge_errors_en, capsize=5, label=\"ROUGE-L F1\", color=\"green\")\n",
    "\n",
    "bars4 = ax.bar(x + width*2, llm_mean_en, width, yerr=llm_errors_en, capsize=5, label=\"LLM Score\", color=\"red\")\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of BLEU, METEOR, ROUGE-L (F1) and LLM Score with Min/Max Error Bars - English Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bleu_mean_en.index, rotation=30, fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danish Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampering_types = df_da[\"tamperingType\"].unique()\n",
    "\n",
    "bleu_mean_da = df_da.groupby(\"tamperingType\")[\"BLEU\"].mean()\n",
    "meteor_mean_da = df_da.groupby(\"tamperingType\")[\"METEOR\"].mean()\n",
    "rouge_mean_da = df_da.groupby(\"tamperingType\")[\"Rougel f\"].mean()\n",
    "llm_mean_da = df_da.groupby(\"tamperingType\")[\"LLM-Sim\"].mean()\n",
    "\n",
    "bleu_min_da = df_da.groupby(\"tamperingType\")[\"BLEU\"].min()\n",
    "bleu_max_da = df_da.groupby(\"tamperingType\")[\"BLEU\"].max()\n",
    "\n",
    "meteor_min_da = df_da.groupby(\"tamperingType\")[\"METEOR\"].min()\n",
    "meteor_max_da = df_da.groupby(\"tamperingType\")[\"METEOR\"].max()\n",
    "\n",
    "rouge_min_da = df_da.groupby(\"tamperingType\")[\"Rougel f\"].min()\n",
    "rouge_max_da = df_da.groupby(\"tamperingType\")[\"Rougel f\"].max()\n",
    "\n",
    "llm_min_da = df_da.groupby(\"tamperingType\")[\"LLM-Sim\"].min()\n",
    "llm_max_da = df_da.groupby(\"tamperingType\")[\"LLM-Sim\"].max()\n",
    "\n",
    "assert bleu_mean_da.index.to_list() == meteor_mean_da.index.to_list() == rouge_mean_da.index.to_list() == llm_mean_da.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_errors_da = [bleu_mean_da - bleu_min_da, bleu_max_da - bleu_mean_da]\n",
    "meteor_errors_da = [meteor_mean_da - meteor_min_da, meteor_max_da - meteor_mean_da]\n",
    "rouge_errors_da = [rouge_mean_da - rouge_min_da, rouge_max_da - rouge_mean_da]\n",
    "llm_errors_da = [llm_mean_da - llm_min_da, llm_max_da - llm_mean_da]\n",
    "\n",
    "x = np.arange(len(tampering_types))  \n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, bleu_mean_da, width, yerr=bleu_errors_da, capsize=5, label=\"BLEU\", color=\"blue\")\n",
    "bars2 = ax.bar(x, meteor_mean_da, width, yerr=meteor_errors_da, capsize=5, label=\"METEOR\", color=\"orange\")\n",
    "bars3 = ax.bar(x + width, rouge_mean_da, width, yerr=rouge_errors_da, capsize=5, label=\"ROUGE-L F1\", color=\"green\")\n",
    "bars4 = ax.bar(x + width*2, llm_mean_da, width, yerr=llm_errors_da, capsize=5, label=\"LLM Score\", color=\"red\")\n",
    "\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Comparison of BLEU, METEOR, ROUGE-L (F1) and LLM Score with Min/Max Error Bars - Danish Dataset\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(bleu_mean_da.index, rotation=30, fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.displot.html\n",
    "\n",
    "tampering_types = df[\"tamperingType\"].unique()\n",
    "\n",
    "columns_of_interest = ['BLEU', 'METEOR', 'Rougel f', 'LLM-Sim']\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    for tam_type in tampering_types:\n",
    "        g = sns.displot(data=df[(df[\"tamperingType\"]==tam_type)], x=col, kde=True, bins = 10)\n",
    "        g.set_axis_labels(f\"{col} Score\", \"Frequency\")\n",
    "        g.set(title = f\"{col} - {tam_type} - Combined Dataset\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.displot.html\n",
    "tampering_types = df_en[\"tamperingType\"].unique()\n",
    "\n",
    "columns_of_interest = ['BLEU', 'METEOR', 'Rougel f', 'LLM-Sim']\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    for tam_type in tampering_types:\n",
    "        g = sns.displot(data=df_en[(df_en[\"tamperingType\"]==tam_type)], x=col, kde=True, bins = 10)\n",
    "        g.set_axis_labels(f\"{col} Score\", \"Frequency\")\n",
    "        g.set(title = f\"{col} - {tam_type} - English Dataset\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.displot.html\n",
    "tampering_types = df_da[\"tamperingType\"].unique()\n",
    "\n",
    "columns_of_interest = ['BLEU', 'METEOR', 'Rougel f', 'LLM-Sim']\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    for tam_type in tampering_types:\n",
    "        g = sns.displot(data=df_da[(df_da[\"tamperingType\"]==tam_type)], x=col, kde=True, bins = 10)\n",
    "        g.set_axis_labels(f\"{col} Score\", \"Frequency\")\n",
    "        g.set(title = f\"{col} - {tam_type} - Danish Dataset\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dfMet = df[['BLEU', 'METEOR', 'Rouge1 r', 'Rouge1 p', 'Rouge1 f', 'Rouge2 r', 'Rouge2 p', 'Rouge2 f', \n",
    "                       'Rougel r', 'Rougel p', 'Rougel f', 'LLM-Sim', 'LLM-Con']]\n",
    "corr = dfMet.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', annot=True, fmt=\".2f\", square=True, linewidths=0.5)\n",
    "\n",
    "plt.title('Metric Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "strategy_means = df.groupby(\"tamperingType\").mean(numeric_only=True)\n",
    "scaler = StandardScaler()\n",
    "normalized = scaler.fit_transform(strategy_means)\n",
    "\n",
    "\n",
    "# Create the linkage matrix and plot dendrogram\n",
    "linked = linkage(normalized, method='ward')\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linked, labels=strategy_means.index.tolist(), leaf_rotation=90)\n",
    "plt.title(\"Hierarchical Clustering of Tampering Strategies\")\n",
    "plt.show()\n",
    "\n",
    "cluster_labels = fcluster(linked, t=3, criterion='maxclust')  # change `t` based on the plot\n",
    "strategy_means['cluster'] = cluster_labels\n",
    "\n",
    "sns.heatmap(strategy_means.drop(\"cluster\", axis=1), annot=True, cmap=\"viridis\", xticklabels=True, yticklabels=strategy_means.index)\n",
    "plt.title(\"Mean Metric Scores per Tampering Strategy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('human_score/humanScoring.csv')\n",
    "\n",
    "with open('human_score/Oskar') as f1, open('human_score/Nhu') as f2, open('human_score/Christina') as f3:\n",
    "    nums1 = [float(line.strip()) for line in f1]\n",
    "    nums2 = [float(line.strip()) for line in f2]\n",
    "    nums3 = [float(line.strip()) for line in f3]\n",
    "\n",
    "mean_values = [(a + b + c) / 3 for a, b, c in zip(nums1, nums2, nums3)]\n",
    "\n",
    "df['humanMean'] = mean_values\n",
    "\n",
    "df.to_csv('human_score/humanScores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"human_score/humanScores.csv\")\n",
    "columns_to_keep = ['tamperingType', 'humanMean']\n",
    "df_filtered = df[columns_to_keep]\n",
    "\n",
    "result = df_filtered.groupby('tamperingType').mean()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"human_score/humanScores.csv\")\n",
    "dfMet = df[['BLEU', 'METEOR', 'Rougel f', 'LLM-Sim', 'humanMean']]\n",
    "corr = dfMet.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', annot=True, fmt=\".2f\", square=True, linewidths=0.5)\n",
    "\n",
    "plt.title(\"Human-metric correlation - All tampering strategies\")\n",
    "plt.show()\n",
    "\n",
    "for x in df[\"tamperingType\"].unique():\n",
    "    data = df[df[\"tamperingType\"]==x]\n",
    "    dfMet = data[['BLEU', 'METEOR', 'Rougel f', 'LLM-Sim', 'humanMean']]\n",
    "    corr = dfMet.corr()\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr, mask=mask, cmap='coolwarm', annot=True, fmt=\".2f\", square=True, linewidths=0.5)\n",
    "\n",
    "    plt.title(f\"Human-metric correlation - {x}\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"human_score/humanScores.csv\")\n",
    "\n",
    "means = [df[\"humanMean\"][i:i+10].mean() for i in range(0, 100, 10)]\n",
    "\n",
    "# Print the result\n",
    "for i, mean in enumerate(means, start=1):\n",
    "    print(f\"Bin {i}: Mean = {mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import krippendorff\n",
    "\n",
    "r1 = pd.read_csv('human_score/Nhu', header=None)\n",
    "r2 = pd.read_csv('human_score/Oskar', header=None)\n",
    "r3 = pd.read_csv('human_score/Christina', header=None)\n",
    "\n",
    "humanData = pd.concat([r1, r2, r3], axis=1)\n",
    "humanData.columns = ['rater1', 'rater2', 'rater3']\n",
    "\n",
    "data = humanData.T.values\n",
    "alpha = krippendorff.alpha(reliability_data=data, level_of_measurement='interval')\n",
    "\n",
    "print(\"Krippendorff’s alpha:\", alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"final_output/combinedOutput_cleaned.csv\"\n",
    "df = pandas.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "std_devs = df.groupby('tamperingType')['LLM-Sim'].std()\n",
    "print(std_devs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "merged_df = pd.merge(std_devs, mean_global[\"LLM-Con\"], on=\"tamperingType\")\n",
    "\n",
    "for i, row in merged_df.iterrows():\n",
    "    plt.text(row[\"LLM-Sim\"], row[\"LLM-Con\"], str(i),\n",
    "             fontsize=7, ha='left', va='bottom')\n",
    "\n",
    "plt.scatter(merged_df['LLM-Sim'], merged_df['LLM-Con'])\n",
    "plt.title('Scatter Plot of LLM Similarity STD vs LLM Evaluation Confidence')\n",
    "plt.xlabel('LLM-Sim Standard Deviation')\n",
    "plt.ylabel('LLM-Con')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
